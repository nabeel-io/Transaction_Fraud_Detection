{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5129ed3d-1c99-478f-8d59-ba1770f99441",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c298e070-d537-4595-9768-daa06b5bcd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle(\"data/train_over_shrink.pickle\")\n",
    "test = pd.read_pickle(\"data/test.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6d7cd42a-c42c-4177-a2a5-12b057cd9bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2f7f0a28-c847-407c-a557-bcc52bcd2933",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ed0bfaa6-88c2-403e-b4c0-7aefb4579489",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_jobs=-1)\n",
    "xgb_clf = xgb.XGBClassifier(n_jobs=-1, use_label_encoder=False)\n",
    "lgbm_clf = lgbm.LGBMClassifier()\n",
    "def model_fit(train):\n",
    "    rfc.fit(train.iloc[:,:-1].to_numpy(), train[\"Class\"].to_numpy())\n",
    "    xgb_clf.fit(train.iloc[:,:-1].to_numpy(), train[\"Class\"].to_numpy())\n",
    "    lgbm_clf.fit(train.iloc[:,:-1].to_numpy(), train[\"Class\"].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5d2bc6c4-b78e-4408-a627-94c422f0e36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:18:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "model_fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d04a72c7-054b-4e99-ba79-705b47264a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nabeel/miniconda3/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/home/nabeel/miniconda3/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_prob = dict()\n",
    "test_prob = dict()\n",
    "\n",
    "train_prob[\"rfc\"] = rfc.predict_proba(train.iloc[:,:-1]).T[1]\n",
    "train_prob[\"xgb\"] = xgb_clf.predict_proba(train.iloc[:,:-1]).T[1]\n",
    "train_prob[\"lgbm\"] = lgbm_clf.predict_proba(train.iloc[:,:-1]).T[1]\n",
    "\n",
    "test_prob[\"rfc\"] = rfc.predict_proba(test.iloc[:,:-1]).T[1]\n",
    "test_prob[\"xgb\"] = xgb_clf.predict_proba(test.iloc[:,:-1]).T[1]\n",
    "test_prob[\"lgbm\"] = lgbm_clf.predict_proba(test.iloc[:,:-1]).T[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ae210336-e02b-4d95-adf5-41c99a5075ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prob = pd.DataFrame(train_prob)\n",
    "test_prob = pd.DataFrame(test_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9fa47eee-3d4b-45d7-a398-5f64d19afe49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     71079\n",
      "           1       0.77      0.80      0.78       123\n",
      "\n",
      "    accuracy                           1.00     71202\n",
      "   macro avg       0.88      0.90      0.89     71202\n",
      "weighted avg       1.00      1.00      1.00     71202\n",
      "\n",
      "[[71049    30]\n",
      " [   25    98]]\n"
     ]
    }
   ],
   "source": [
    "test_probability = test_prob.mean(axis=1).to_numpy()\n",
    "y_pred = []\n",
    "for prob in test_probability:\n",
    "    if prob >=0.5:\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)\n",
    "print(classification_report(test[\"Class\"], y_pred))\n",
    "print(confusion_matrix(test[\"Class\"], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3055da2f-d6c9-4d20-98e2-9b2fc7ba1454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71202,)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_probability.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7b6af419-3518-47bf-bc19-b3a77ff27c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     71079\n",
      "           1       0.78      0.80      0.79       123\n",
      "\n",
      "    accuracy                           1.00     71202\n",
      "   macro avg       0.89      0.90      0.89     71202\n",
      "weighted avg       1.00      1.00      1.00     71202\n",
      "\n",
      "[[71051    28]\n",
      " [   25    98]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(train_prob, train[\"Class\"])\n",
    "test_probability = lr.predict(test_prob)\n",
    "y_pred = []\n",
    "for prob in test_probability:\n",
    "    if prob >=0.5:\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)\n",
    "print(classification_report(test[\"Class\"], y_pred))\n",
    "print(confusion_matrix(test[\"Class\"], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715beb09-eecd-4fb1-8b5a-baa06ba3180a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
