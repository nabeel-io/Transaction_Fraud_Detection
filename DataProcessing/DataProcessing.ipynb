{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30a6a1c2-63da-4678-b7a6-42c4c38a9926",
   "metadata": {},
   "source": [
    "## **Data Processing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c76f38e-d5a2-49bd-8fb7-c766ef10994b",
   "metadata": {},
   "source": [
    "### **Table of Contents**\n",
    "1. Importing libraries\n",
    "2. Importing function\n",
    "3. Importing Dataframe\n",
    "4. Reducing Memory Usage\n",
    "5. Target Class proportion\n",
    "6. Train/Test split\n",
    "7. Conversion to different file formats\n",
    "8. Memory Usage\n",
    "9. Train Test conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53648c52-ea91-421f-8db7-8cf42e00d4f2",
   "metadata": {},
   "source": [
    "### **Importing libraries**\n",
    "*Importing essential libraries like `os` for making directory, `zipfile` for extracting data from zip folder, `pandas` to process\n",
    "the dataframe and `pyarrow` for feather and parquet*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e834cb5d-9285-4e70-920b-a0b069f97e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0df355a-c7da-4524-a12b-e6e9c0fbe814",
   "metadata": {},
   "source": [
    "### **Import Function**\n",
    "*Importing data from `Kaggle API`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c7d727d-2b5a-4255-8364-2c5aa7081900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data():\n",
    "    if not os.path.exists(\"customer_transaction_prediction/\"):\n",
    "        os.makedirs(\"data\")\n",
    "        !kaggle datasets download -d mlg-ulb/creditcardfraud -p data/\n",
    "        with zipfile.ZipFile(\"data/creditcardfraud.zip\", \"r\") as zipdata:\n",
    "            zipdata.extractall(\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b84863a9-55f3-4e91-9231-68f9ac3acdaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/nabeel/.kaggle/kaggle.json'\n",
      "Downloading creditcardfraud.zip to data\n",
      "100%|██████████████████████████████████████| 66.0M/66.0M [00:18<00:00, 4.41MB/s]\n",
      "100%|██████████████████████████████████████| 66.0M/66.0M [00:18<00:00, 3.64MB/s]\n"
     ]
    }
   ],
   "source": [
    "import_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cf4099-a3c6-4972-9773-ea850a3d5cd8",
   "metadata": {},
   "source": [
    "### **Importing Dataframe**\n",
    "*The dataframe `df` consist of 29 attributes and 1 target class with 284,807 instances using 67.4 Mb of memory without null values*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45e758a6-3cf4-4889-9c03-5dda7ca99f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/creditcard.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f4a0de-3e4f-4899-803e-a2562af7eb16",
   "metadata": {},
   "source": [
    "### **Reducing Memory Usage**\n",
    "*Reducing the size of the dataset without significantly effecting the precision of sample values. \n",
    "Converting the target class to `int16` and column variables to `float32` data type.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a343114-cf2b-46d0-934a-97e7d535dde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reducing the size of dataset without effecting the precision of sample values\n",
    "def reduce(df):\n",
    "    dict_dtypes = dict(df.dtypes)\n",
    "    for col, dtype in dict_dtypes.items():\n",
    "        if dtype == \"float64\":\n",
    "            df[col] = df[col].astype(\"float32\")\n",
    "        elif dtype == \"int64\":\n",
    "            df[col] = df[col].astype(\"int16\")\n",
    "        else:\n",
    "            pass\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae13054b-e480-4553-a9ce-d918f989c09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df = reduce(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041c7d33-bd51-45d6-a644-9f99a276bf49",
   "metadata": {},
   "source": [
    "### **Target Class proportion**\n",
    "*Majority of instances are non fradulent in nature, just 1.7% of instances consist of fradulent payment.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "277962bf-d25d-4018-9f31-e1745ed84ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.998273\n",
       "1    0.001727\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the weight of each class\n",
    "df[\"Class\"].value_counts()/len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834d89ad-3052-40a5-af82-5ec69e0e8468",
   "metadata": {},
   "source": [
    "### **Train/Test Split**\n",
    "*Splitting the dataframe into train and test sets using stratified sampling which preserves the proportion of target class.\n",
    "Keeping 25% of instances for test and rest for training.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e43ee6c1-1438-4b47-8e64-33926bdd215e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and testing sets using stratified fold\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(reduced_df.iloc[:, :-1], \n",
    "                                                reduced_df[\"Class\"],\n",
    "                                                stratify=reduced_df[\"Class\"],\n",
    "                                                test_size=0.25,\n",
    "                                                random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f378d36e-7ba7-4a19-b217-cc021b8c82ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([xtrain, ytrain], axis=1)\n",
    "train = train.reset_index(drop=True)\n",
    "test = pd.concat([xtest, ytest], axis=1)\n",
    "test = test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bb82623-d1fc-49e4-a09d-ea792355c85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set proportions: \n",
      "0    0.998273\n",
      "1    0.001727\n",
      "Name: Class, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# target class proportions are preserved\n",
    "print(\"train set proportions: \")\n",
    "print(train[\"Class\"].value_counts()/len(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a655c623-44f9-463b-8bfe-9d14d427ee44",
   "metadata": {},
   "source": [
    "### **Conversion to different file formats**\n",
    "*We convert our processed data to three different file formats to compare there conversion speed and there read speed in order \n",
    "to get the file format which is faster to read and write*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b54b3b3a-f889-49e9-bab2-bb300f701cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading and Writing in Pickle\n",
      "CPU times: user 0 ns, sys: 47.1 ms, total: 47.1 ms\n",
      "Wall time: 45.9 ms\n",
      "CPU times: user 2.43 ms, sys: 8.59 ms, total: 11 ms\n",
      "Wall time: 9.92 ms\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading and Writing in Pickle\")\n",
    "%time df.to_pickle(\"data/df.pickle\")\n",
    "%time df = pd.read_pickle(\"data/df.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "326839d8-3bdd-4230-a804-8bb690df7a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading and Writing in Feather\n",
      "CPU times: user 184 ms, sys: 39.8 ms, total: 224 ms\n",
      "Wall time: 75.7 ms\n",
      "CPU times: user 57.3 ms, sys: 52.7 ms, total: 110 ms\n",
      "Wall time: 25.8 ms\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading and Writing in Feather\")\n",
    "%time df.to_feather(\"data/df.feather\")\n",
    "%time df = pd.read_feather(\"data/df.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6aaa232-ad1b-420c-a8cf-4ac401d6f0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading and Writing in Parquet\n",
      "CPU times: user 817 ms, sys: 45.1 ms, total: 862 ms\n",
      "Wall time: 814 ms\n",
      "CPU times: user 202 ms, sys: 93.7 ms, total: 295 ms\n",
      "Wall time: 125 ms\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading and Writing in Parquet\")\n",
    "%time df.to_parquet(\"data/df.parquet\")\n",
    "%time df = pd.read_parquet(\"data/df.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61835cd4-a213-4ae8-8958-cd31753c5528",
   "metadata": {},
   "source": [
    "*Out of pickle, feather and parquet file format we find pickle to have the fastest read and and write speed and \n",
    "we will prefer to use this format to import data for rest of the project work*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd27a39-8026-402b-b6d5-14bed1727bb1",
   "metadata": {},
   "source": [
    "### **Memory usage**\n",
    "*Out of the three file formats pickle and feather use the least memory, almost reducing the size of data four times than that of\n",
    "orignal csv file.We prefer to use pickle in our case becuase it is much faster in read and write speeds than other file formats*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfffea58-2394-444f-8b1b-cb96e122d4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144M -rw-rw-r-- 1 nabeel 144M Jul 16 21:07 data/creditcard.csv\n",
      " 32M -rw-rw-r-- 1 nabeel  32M Jul 16 21:07 data/df.feather\n",
      " 49M -rw-rw-r-- 1 nabeel  49M Jul 16 21:07 data/df.parquet\n",
      " 34M -rw-rw-r-- 1 nabeel  34M Jul 16 21:07 data/df.pickle\n"
     ]
    }
   ],
   "source": [
    "!ls -GFlash data/creditcard.csv data/df.pickle data/df.feather data/df.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7cc335-bc4f-4655-94d1-3d68e9509a3d",
   "metadata": {},
   "source": [
    "### **Train Test conversion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06b43e47-29e3-4af1-8ea8-2131aa063cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_pickle(\"data/train.pickle\")\n",
    "test.to_pickle(\"data/test.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bb96fd-3ff5-4128-80da-c679387ae584",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d2fcf0-e4c5-447e-9230-f2e239fd0eb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
